# -*- coding: utf-8 -*-
"""project4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_7ju1PttT2VpQ8CxAzcVhcFfzVrm_bFi
"""

"""
Author: Jungmyung Lee
This prototype was developed together with a teammate
who is a college student majoring in computer science during our LifeStep internship.


Real-Time EMG Regression Pipeline (TD + CNN + TCN) From my internship dataset.
---------------------------------------------------
This script is a prototype that my teammate and I built as a lightweight,
real-time-capable EMG processing model designed for prosthetic control and
continuous joint-angle prediction.


Model Purpose
-------------
The goal is to convert multi-channel surface EMG signals into continuous,
low-latency joint-angle estimates suitable for embedded prosthetic devices.


Why 150 ms Window + 10 ms Hop?
------------------------------
A 150 ms analysis window provides:
- enough samples (150 points @ 1000 Hz) to capture muscle activation patterns
- low delay while maintaining stable features
A 10 ms hop (~100 Hz control rate) enables smooth, real-time updates.

Why 3 Segments for TD Features?
-------------------------------
Segmenting the 150 ms window into 3 smaller temporal segments preserves
short-term structure in EMG bursts while avoiding feature estimation noise.
Each segment contributes 5 TD features → 15 features/channel.

Why the 5 TD Features? (Hudgins set)
------------------------------------
MAV, RMS, WL, ZC, and SSC are chosen because they:
- are extremely fast to compute (microcontroller-friendly)
- provide complementary information (amplitude, frequency, complexity)
- are widely validated in EMG pattern-recognition literature

-were originally introduced and validated in
Hudgins et al. (1993), "A new strategy for multifunction myoelectric control,"
which established these TD features as a robust baseline for EMG pattern recognition
-include RMS, which more recent EMG studies identify as one of the most reliable amplitude
estimators due to its strong correlation with muscle activation levels
-This source is useful for choosing efficient 5 TD features.

Why CNN + TCN Architecture?
---------------------------
CNN (1D) extracts spatial/channel-wise structure:
- two layers (16 → 32 filters) with kernel size 3 efficiently compress
  the TD feature map into a compact representation.

TCN models time-dependency within each 150 ms window:
- dilated convolutions (rates 1 and 2) capture short- and mid-range temporal
  dependencies without the computational cost of RNNs/LSTMs.
- residual blocks improve stability and prevent gradient degradation.

Why These Hyperparameters?
---------------------------
- 16/32 filters: light enough for embedded implementation but expressive
- kernel size 3: commonly optimal for short EMG-derived sequences
- ReLU activation: low computation cost and stable convergence
- Global average pooling: reduces model size and prevents overfitting
- Final FC layer: maps extracted features → continuous joint-angle output

Overall Pipeline Summary
-------------------------
Raw EMG → TD extraction (3×5 features) → [channels × 15]
→ CNN compression → TCN temporal modeling
→ FC regression → Continuous joint-angle estimate

In my experiments, this architecture provides:
- real-time performance (<10 ms inference on small hardware)
- robustness to EMG variations
- compact feature representation suitable for prosthetic control
"""

import os
import math
import random
import numpy as np
import scipy.io as sio
import scipy.signal as signal


import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader


# -----------------------------
# 0) Reproducibility
# -----------------------------
def set_seed(seed=42):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)


# -----------------------------
# 1) EMG extractor for QTM .mat
# -----------------------------
def extract_emg_from_qtm_mat(path, min_channels=8, prefer_fs=1000):
    """
    Attempts to find the most EMG-like Analog board in a QTM export.
    Returns:
        emg: [channels, samples]
        fs: int
    """
    mat = sio.loadmat(path)
    top_keys = [k for k in mat.keys() if not k.startswith("__")]
    if not top_keys:
        raise ValueError("No data keys found in .mat")

    rec = mat[top_keys[0]]
    # QTM struct often stored like mat[key][0,0]
    if isinstance(rec, np.ndarray) and rec.dtype.names is not None:
        rec = rec[0, 0]

    if not hasattr(rec, "dtype") or rec.dtype.names is None:
        raise ValueError("Top-level record does not look like a QTM struct.")

    if "Analog" not in rec.dtype.names:
        raise ValueError("No Analog field found. This may not be a QTM export.")

    analog = rec["Analog"]

    best = None
    for i in range(analog.shape[1]):
        b = analog[0, i]
        try:
            fs = float(np.squeeze(b["Frequency"]))
            nchan = int(np.squeeze(b["NrOfChannels"]))
            data = b["Data"]  # shape [channels, samples]
        except Exception:
            continue

        if data is None or not hasattr(data, "ndim") or data.ndim != 2:
            continue

        score = 0
        if nchan >= min_channels:
            score += 10
        score += max(0, 5 - abs(fs - prefer_fs) / 200)
        score += min(5, nchan / 4)

        if best is None or score > best[0]:
            best = (score, fs, nchan, data)

    if best is None:
        raise ValueError("No suitable analog board for EMG found.")

    _, fs, nchan, data = best
    return data.astype(np.float32), int(round(fs))

# -----------------------------
# 1-1) Simple EMG preprocessing
# -----------------------------
def simple_emg_preprocess(emg, fs, low=20.0, high=450.0, notch=60.0, q=30.0):
    """
    Simple EMG preprocessing:
    - remove DC offset
    - apply notch filter at powerline frequency (e.g., 60 Hz)
    - apply band-pass filter in typical EMG range (e.g., 20–450 Hz)

    emg: [channels, samples]
    fs:  sampling rate (Hz)
    """
    # 1) DC offset removal
    x = emg - emg.mean(axis=1, keepdims=True)

    # 2) Notch filter (powerline)
    b_notch, a_notch = signal.iirnotch(notch, q, fs=fs)
    x = signal.filtfilt(b_notch, a_notch, x, axis=1)

    # 3) Band-pass filter
    nyq = fs * 0.5
    low_n = low / nyq
    high_n = high / nyq
    b_bp, a_bp = signal.butter(4, [low_n, high_n], btype="band")
    x = signal.filtfilt(b_bp, a_bp, x, axis=1)

    return x.astype(np.float32)


# -----------------------------
# 2) TD features (Hudgins 5)
# -----------------------------
def mav(x): return float(np.mean(np.abs(x)))
def rms(x): return float(np.sqrt(np.mean(x**2) + 1e-12))
def wl(x):  return float(np.sum(np.abs(np.diff(x))))

def zc(x, threshold=0.01):
    x1, x2 = x[:-1], x[1:]
    return float(np.sum(((x1 * x2) < 0) & (np.abs(x1 - x2) >= threshold)))

def ssc(x, threshold=0.01):
    dx1 = x[1:-1] - x[:-2]
    dx2 = x[2:]   - x[1:-1]
    return float(np.sum(((dx1 * dx2) < 0) & (np.abs(dx1 - dx2) >= threshold)))

TD_FUNCS = [mav, rms, wl, zc, ssc]


def extract_td_features_window(emg_window, n_segments=3):
    """
    emg_window: [channels, win_len]
    returns: [channels, n_segments*5] -> [ch, 15]
    """
    ch, L = emg_window.shape
    seg_len = L // n_segments
    feats = []

    for s in range(n_segments):
        start = s * seg_len
        end = (s + 1) * seg_len if s < n_segments - 1 else L
        seg = emg_window[:, start:end]

        seg_feats = np.zeros((ch, len(TD_FUNCS)), dtype=np.float32)
        for ci in range(ch):
            x = seg[ci]
            seg_feats[ci, 0] = mav(x)
            seg_feats[ci, 1] = rms(x)
            seg_feats[ci, 2] = wl(x)
            seg_feats[ci, 3] = zc(x)
            seg_feats[ci, 4] = ssc(x)

        feats.append(seg_feats)

    return np.concatenate(feats, axis=1).astype(np.float32)


# -----------------------------
# 3) Label loading (robust)
# -----------------------------
def load_labels_from_npy(npy_path):
    y = np.load(npy_path)
    if y.ndim == 1:
        y = y[:, None]
    return y.astype(np.float32)


def load_labels_from_mat(mat_path, key):
    m = sio.loadmat(mat_path)
    if key not in m:
        raise KeyError(f"Key '{key}' not found in {mat_path}. Available keys: {list(m.keys())}")
    y = m[key]
    y = np.squeeze(y)
    if y.ndim == 1:
        y = y[:, None]
    return y.astype(np.float32)


def heuristic_find_label_in_mat(qtm_mat_path, key_candidates):
    """
    Best-effort fallback for quick experiments.

    In my normal workflow, I load joint-angle labels from a clean external file
    (e.g., a .npy or .mat exported from QTM or Visual3D).
    This helper only tries to guess a numeric label array from the same MAT file
    by checking a few common key names (e.g., 'angles', 'knee_angle', etc.).
    """
    m = sio.loadmat(qtm_mat_path)
    for k in key_candidates:
        if k in m:
            arr = np.squeeze(m[k])
            if arr.ndim >= 1 and np.issubdtype(arr.dtype, np.number):
                if arr.ndim == 1:
                    arr = arr[:, None]
                return arr.astype(np.float32), k
    return None, None


# -----------------------------
# 4) Build TD windows + align labels by time
# -----------------------------
def build_td_and_labels(
    emg, fs_emg,
    y, fs_y,
    window_ms=150, hop_ms=10,
    n_segments=3, use_channels=8
):
    """
    emg: [channels, samples]
    y:   [samples_y, dof]
    Returns:
        X: [n_windows, use_channels, 15]
        Y: [n_windows, dof]
    Alignment:
        - label index chosen by center-of-window time
    """
    emg = emg[:use_channels]
    ch, samples = emg.shape

    win_len = int(fs_emg * window_ms / 1000)
    hop_len = int(fs_emg * hop_ms / 1000)

    X_list = []
    Y_list = []

    y_len = y.shape[0]

    for start in range(0, samples - win_len + 1, hop_len):
        end = start + win_len
        w = emg[:, start:end]
        feats = extract_td_features_window(w, n_segments=n_segments)  # [ch, 15]

        # time alignment (center of window)
        center_emg_idx = start + win_len // 2
        t_sec = center_emg_idx / float(fs_emg)
        y_idx = int(round(t_sec * fs_y))

        if 0 <= y_idx < y_len:
            X_list.append(feats)
            Y_list.append(y[y_idx])

    if len(X_list) == 0:
        raise ValueError("No aligned windows found. Check fs_emg/fs_y or label length.")

    X = np.stack(X_list, axis=0).astype(np.float32)
    Y = np.stack(Y_list, axis=0).astype(np.float32)
    return X, Y


# -----------------------------
# 5) Normalizer (per-position)
# -----------------------------
class TDNormalizer:
    """
    Computes mean/std for each [channel, feature_time] position
    on training data only.
    """
    def __init__(self, eps=1e-8):
        self.eps = eps
        self.mean = None  # [C, T]
        self.std = None   # [C, T]

    def fit(self, X):
        # X: [N, C, T]
        self.mean = X.mean(axis=0)
        self.std = X.std(axis=0)
        self.std = np.maximum(self.std, self.eps)

    def transform(self, X):
        return (X - self.mean) / self.std

    def fit_transform(self, X):
        self.fit(X)
        return self.transform(X)


# -----------------------------
# 6) Dataset
# -----------------------------
class EMGWindowDataset(Dataset):
    def __init__(self, X, Y):
        self.X = torch.from_numpy(X).float()
        self.Y = torch.from_numpy(Y).float()

    def __len__(self):
        return self.X.shape[0]

    def __getitem__(self, idx):
        return self.X[idx], self.Y[idx]


# -----------------------------
# 7) CNN + TCN model (as specified)
# -----------------------------
class CNNBackbone(nn.Module):
    def __init__(self, in_ch, f1=16, f2=32, k=3):
        super().__init__()
        pad = k // 2
        self.net = nn.Sequential(
            nn.Conv1d(in_ch, f1, kernel_size=k, padding=pad),
            nn.ReLU(),
            nn.Conv1d(f1, f2, kernel_size=k, padding=pad),
            nn.ReLU(),
        )

    def forward(self, x):
        return self.net(x)


class TemporalBlock(nn.Module):
    def __init__(self, in_ch, out_ch, k=3, dilation=1):
        super().__init__()
        # "same-ish" padding for short sequences
        pad = (k - 1) * dilation // 2

        self.conv1 = nn.Conv1d(in_ch, out_ch, k, dilation=dilation, padding=pad)
        self.conv2 = nn.Conv1d(out_ch, out_ch, k, dilation=dilation, padding=pad)
        self.relu = nn.ReLU()
        self.down = nn.Conv1d(in_ch, out_ch, 1) if in_ch != out_ch else None

    def forward(self, x):
        out = self.relu(self.conv1(x))
        out = self.relu(self.conv2(out))
        res = x if self.down is None else self.down(x)
        return out + res


class TCNHead(nn.Module):
    def __init__(self, in_ch, hidden=32, k=3, dilations=(1, 2)):
        super().__init__()
        layers = []
        ch = in_ch
        for d in dilations:
            layers.append(TemporalBlock(ch, hidden, k=k, dilation=d))
            ch = hidden
        self.net = nn.Sequential(*layers)

    def forward(self, x):
        return self.net(x)


class TD_CNN_TCN_Regressor(nn.Module):
    def __init__(self, in_ch=8, out_dof=1):
        super().__init__()
        self.cnn = CNNBackbone(in_ch, f1=16, f2=32, k=3)
        self.tcn = TCNHead(32, hidden=32, k=3, dilations=(1, 2))
        self.pool = nn.AdaptiveAvgPool1d(1)
        self.fc = nn.Linear(32, out_dof)

    def forward(self, x):
        # x: [B, C=8, T=15]
        x = self.cnn(x)
        x = self.tcn(x)
        x = self.pool(x).squeeze(-1)  # [B, 32]
        return self.fc(x)             # [B, out_dof]


# -----------------------------
# 8) Train / Eval utilities
# -----------------------------
def split_indices(n, train_ratio=0.8, val_ratio=0.1, seed=42):
    idx = np.arange(n)
    rng = np.random.default_rng(seed)
    rng.shuffle(idx)

    n_train = int(n * train_ratio)
    n_val = int(n * val_ratio)

    train_idx = idx[:n_train]
    val_idx = idx[n_train:n_train + n_val]
    test_idx = idx[n_train + n_val:]
    return train_idx, val_idx, test_idx


def run_epoch(model, loader, criterion, optimizer=None, device="cpu"):
    is_train = optimizer is not None
    model.train() if is_train else model.eval()

    total_loss = 0.0
    n_total = 0

    with torch.set_grad_enabled(is_train):
        for Xb, Yb in loader:
            Xb = Xb.to(device)
            Yb = Yb.to(device)

            pred = model(Xb)
            loss = criterion(pred, Yb)

            if is_train:
                optimizer.zero_grad()
                loss.backward()
                optimizer.step()

            bs = Xb.size(0)
            total_loss += loss.item() * bs
            n_total += bs

    return total_loss / max(1, n_total)


def train_model(
    model, train_loader, val_loader,
    lr=1e-3, weight_decay=0.0,
    epochs=50, patience=8,
    device="cpu",
    ckpt_path="td_cnn_tcn_best.pt"
):
    criterion = nn.MSELoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)

    best_val = float("inf")
    bad = 0

    for ep in range(1, epochs + 1):
        tr_loss = run_epoch(model, train_loader, criterion, optimizer, device)
        va_loss = run_epoch(model, val_loader, criterion, None, device)

        print(f"[Epoch {ep:03d}] train={tr_loss:.6f}  val={va_loss:.6f}")

        if va_loss < best_val - 1e-6:
            best_val = va_loss
            bad = 0
            torch.save({
                "model_state": model.state_dict(),
            }, ckpt_path)
        else:
            bad += 1
            if bad >= patience:
                print("Early stopping triggered.")
                break

    # Load best
    if os.path.exists(ckpt_path):
        state = torch.load(ckpt_path, map_location=device)
        model.load_state_dict(state["model_state"])

    return model


def evaluate_rmse(model, loader, device="cpu"):
    model.eval()
    preds = []
    trues = []

    with torch.no_grad():
        for Xb, Yb in loader:
            Xb = Xb.to(device)
            pred = model(Xb).cpu().numpy()
            preds.append(pred)
            trues.append(Yb.numpy())

    preds = np.concatenate(preds, axis=0)
    trues = np.concatenate(trues, axis=0)

    mse = np.mean((preds - trues) ** 2, axis=0)
    rmse = np.sqrt(mse)
    return rmse, preds, trues


# -----------------------------
# 9) MAIN (training entry)
# -----------------------------
if __name__ == "__main__":
    set_seed(42)
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print("Device:", device)

    # =============================
    # USER CONFIG (modify as needed)
    # =============================
    qtm_mat_path = "/content/EMG_session01.mat"  # or local path

    # ---- Label options ----
    # Preferred workflow:
    # In my internship dataset, joint angles were exported as a clean external file
    # (e.g., 'joint_angles.npy'). In practice, I normally load that file directly.
    #
    # Example:
    # label_npy_path = "joint_angles.npy"  # TODO: replace with your actual label file
    label_npy_path = None  # kept as None here to avoid hard-coding a private path

    # Optional: if labels are stored in a separate .mat file with a known key.
    label_mat_path = None  # e.g., "joint_angles.mat"
    label_mat_key  = None  # e.g., "joint_angles"

    # Experimental / fallback:
    # If no explicit label file is provided, this helper tries to guess
    # a numeric angle array directly from the QTM .mat by checking common names.
    label_key_candidates = [
        "angle", "angles", "joint_angle", "joint_angles",
        "knee_angle", "hip_angle", "ankle_angle",
        "KneeAngle", "HipAngle", "AnkleAngle"
    ]


    # Sampling rates
    fs_emg_prefer = 1000
    fs_label = 1000

    # Window params
    window_ms = 150
    hop_ms = 10
    n_segments = 3
    use_channels = 8

    # Training params
    batch_size = 128
    epochs = 60
    patience = 10
    lr = 1e-3
    weight_decay = 0.0
    ckpt_path = "td_cnn_tcn_best.pt"


    # =============================
    # 1) Load EMG
    # =============================
    emg, fs_emg = extract_emg_from_qtm_mat(
        qtm_mat_path,
        min_channels=use_channels,
        prefer_fs=fs_emg_prefer
    )
    print("EMG:", emg.shape, "fs_emg =", fs_emg)

    # Simple EMG preprocessing (DC removal + notch + band-pass)
    emg = simple_emg_preprocess(emg, fs_emg)


    # =============================
    # 2) Load Labels
    # =============================
    y = None

    # Preferred: load a clean external label file (my normal workflow).
    if label_npy_path is not None:
        y = load_labels_from_npy(label_npy_path)
        print("Loaded labels from npy:", y.shape)

    # Alternative: load from a separate .mat with a known key.
    elif label_mat_path is not None and label_mat_key is not None:
        y = load_labels_from_mat(label_mat_path, label_mat_key)
        print("Loaded labels from mat:", y.shape, "key =", label_mat_key)

    else:
        # Fallback for quick experiments:
        # try to guess a joint-angle array directly from the same QTM .mat file.
        y_found, k_found = heuristic_find_label_in_mat(qtm_mat_path, label_key_candidates)
        if y_found is None:
            raise ValueError(
                "No labels found.\n"
                "Provide label_npy_path OR (label_mat_path + label_mat_key),\n"
                "or enable the heuristic with appropriate key candidates."
            )
        y = y_found
        print("Heuristically found label key:", k_found, "shape:", y.shape)


    # Ensure 2D
    if y.ndim == 1:
        y = y[:, None]

    out_dof = y.shape[1]
    print("Output DOF:", out_dof)

    # =============================
    # 3) Build TD windows + Align labels
    # =============================
    X, Y = build_td_and_labels(
        emg, fs_emg,
        y, fs_label,
        window_ms=window_ms, hop_ms=hop_ms,
        n_segments=n_segments, use_channels=use_channels
    )
    print("X:", X.shape, "Y:", Y.shape)  # X [N, 8, 15], Y [N, dof]

    # =============================
    # 4) Split
    # =============================
    n = X.shape[0]
    train_idx, val_idx, test_idx = split_indices(n, 0.8, 0.1, seed=42)

    X_train, Y_train = X[train_idx], Y[train_idx]
    X_val,   Y_val   = X[val_idx],   Y[val_idx]
    X_test,  Y_test  = X[test_idx],  Y[test_idx]

    # =============================
    # 5) Normalize (train-only)
    # =============================

    # TODO:
    # For deployment, also serialize `norm.mean` and `norm.std`
    # so that the same normalization can be applied on-device.

    norm = TDNormalizer()
    X_train = norm.fit_transform(X_train)
    X_val = norm.transform(X_val)
    X_test = norm.transform(X_test)

    # =============================
    # 6) DataLoaders
    # =============================
    train_ds = EMGWindowDataset(X_train, Y_train)
    val_ds   = EMGWindowDataset(X_val, Y_val)
    test_ds  = EMGWindowDataset(X_test, Y_test)

    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, drop_last=False)
    val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, drop_last=False)
    test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False, drop_last=False)

    # =============================
    # 7) Model
    # =============================
    model = TD_CNN_TCN_Regressor(in_ch=use_channels, out_dof=out_dof).to(device)
    print(model)

    # =============================
    # 8) Train
    # =============================
    model = train_model(
        model, train_loader, val_loader,
        lr=lr, weight_decay=weight_decay,
        epochs=epochs, patience=patience,
        device=device,
        ckpt_path=ckpt_path
    )

    # =============================
    # 9) Evaluate
    # =============================
    rmse, preds, trues = evaluate_rmse(model, test_loader, device=device)
    print("Test RMSE per DOF:", rmse)

    print("Done. Best model saved to:", ckpt_path)